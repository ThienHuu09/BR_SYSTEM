import streamlit as st
import pandas as pd
import logging
import numpy as np
from whoosh.index import create_in, open_dir
from whoosh.fields import Schema, TEXT, NUMERIC
from whoosh.qparser import MultifieldParser, QueryParser
from diskcache import Cache
from concurrent.futures import ThreadPoolExecutor, TimeoutError
import ollama
import os
from pathlib import Path
import time
import requests
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from scipy.sparse import csr_matrix

# C·∫•u h√¨nh logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# C·∫•u h√¨nh Streamlit
st.set_page_config(layout="wide", page_title="Book Recommendation ", initial_sidebar_state="expanded")

# ƒê∆∞·ªùng d·∫´n index Whoosh v√† cache
INDEX_DIR = Path("indexdir")
CACHE_DIR = Path("./cache")

# T·∫°o schema Whoosh
schema = Schema(
    title=TEXT(stored=True),
    authors=TEXT(stored=True),
    published_year=NUMERIC(stored=True),
    category=TEXT(stored=True),
    description=TEXT(stored=True),
    thumbnail=TEXT(stored=True),
    ratings_count=NUMERIC(stored=True)
)

# Kh·ªüi t·∫°o index Whoosh
def create_or_open_index(books_df):
    if not INDEX_DIR.exists():
        os.makedirs(INDEX_DIR)
        ix = create_in(INDEX_DIR, schema)
        writer = ix.writer()
        for _, row in books_df.iterrows():
            writer.add_document(
                title=str(row['title']),
                authors=str(row['authors']),
                published_year=int(row['published_year']) if pd.notna(row['published_year']) else 0,
                category=str(row['category']),
                description=str(row['description']),
                thumbnail=str(row['thumbnail'] if pd.notna(row['thumbnail']) else ''),
                ratings_count=float(row['ratings_count']) if pd.notna(row['ratings_count']) else 0
            )
        writer.commit()
        logger.info(f"Created new Whoosh index in {INDEX_DIR}")
    else:
        ix = open_dir(INDEX_DIR)
    return ix

# Kh·ªüi t·∫°o cache
cache = Cache(CACHE_DIR)

# S·ªë lu·ªìng t√¨m ki·∫øm song song
executor = ThreadPoolExecutor(max_workers=2)

# Cache d·ªØ li·ªáu t·ª´ books.csv
@st.cache_data(hash_funcs={pd.DataFrame: lambda x: hash(x.to_string())})
def load_data():
    try:
        if not os.path.exists('books.csv'):
            logger.error("File 'books.csv' not found")
            st.error("Kh√¥ng t√¨m th·∫•y file 'books.csv'. Vui l√≤ng ki·ªÉm tra l·∫°i.")
            return pd.DataFrame()
        # ƒê·ªçc file m√† kh√¥ng ch·ªâ ƒë·ªãnh usecols ƒë·ªÉ ki·ªÉm tra t·∫•t c·∫£ c·ªôt
        books_df = pd.read_csv('books.csv', dtype={
            'title': 'string', 'description': 'string', 'authors': 'string',
            'published_year': 'Int32', 'ratings_count': 'float32', 'thumbnail': 'string'
        })
        # Ki·ªÉm tra c√°c c·ªôt c√≥ trong file
        expected_columns = {'title', 'description', 'authors', 'published_year', 'ratings_count', 'thumbnail'}
        missing_columns = expected_columns - set(books_df.columns)
        if missing_columns:
            logger.error(f"Missing columns in books.csv: {missing_columns}")
            st.error(f"File 'books.csv' thi·∫øu c√°c c·ªôt: {missing_columns}")
            return pd.DataFrame()
        # Ki·ªÉm tra c·ªôt category
        if 'category' not in books_df.columns:
            logger.warning("Column 'category' not found, adding empty category")
            books_df['category'] = 'None'
        else:
            logger.debug(f"Found column 'category' with values: {books_df['category'].head()}")

        books_df.fillna({
            'description': 'None', 'authors': 'None',
            'category': 'None', 'thumbnail': ''
        }, inplace=True)
        books_df['ratings_count'] = books_df['ratings_count'].fillna(0)
        # Thay th·∫ø chu·ªói r·ªóng b·∫±ng kho·∫£ng tr·∫Øng ƒë·ªÉ tr√°nh l·ªói vector h√≥a
        books_df['category'] = books_df['category'].replace('', ' ')
        logger.info(f"Loaded dataset with {len(books_df)} books")
        return books_df
    except Exception as e:
        logger.error(f"Error loading data: {str(e)}")
        st.error(f"Kh√¥ng th·ªÉ t·∫£i d·ªØ li·ªáu s√°ch: {str(e)}")
        return pd.DataFrame()

@st.cache_resource
def compute_similarity(df):
    try:
        # ƒê·∫£m b·∫£o t·∫•t c·∫£ c·ªôt l√† chu·ªói v√† kh√¥ng ch·ª©a gi√° tr·ªã kh√¥ng h·ª£p l·ªá
        combined_features = (df['title'].astype(str).replace('', ' ') + ' ' +
                            df['description'].astype(str).replace('', ' ') + ' ' +
                            df['category'].astype(str).replace('', ' ') + ' ' +
                            df['authors'].astype(str).replace('', ' '))
        vectorizer = TfidfVectorizer(stop_words='english', max_features=5000, max_df=1.0, min_df=1)
        tfidf_matrix = vectorizer.fit_transform(combined_features)
        sparse_tfidf = csr_matrix(tfidf_matrix)
        similarity_matrix = cosine_similarity(sparse_tfidf)
        logger.debug(f"Similarity matrix shape: {similarity_matrix.shape}, df shape: {df.shape[0]}")
        if similarity_matrix.shape[0] != df.shape[0]:
            logger.warning(f"Similarity matrix size ({similarity_matrix.shape[0]}) does not match df size ({df.shape[0]})")
        return similarity_matrix
    except Exception as e:
        logger.error(f"Error computing similarity: {str(e)}")
        return None

@st.cache_data
def mistral_search(query):
    try:
        future = executor.submit(ollama.chat, model="mistral", messages=[
            {"role": "system", "content": "You are a book recommendation assistant. Only return titles that are highly relevant to the query based on scientific or factual content, authors, or publication years."},
            {"role": "user", "content": f"Find relevant book titles for: {query}"}
        ])
        response = future.result(timeout=10)
        return response["message"]["content"].strip()
    except TimeoutError:
        logger.warning(f"Mistral query for '{query}' timed out after 10s")
        return "Kh√¥ng th·ªÉ t√¨m ki·∫øm b·∫±ng Mistral"
    except Exception as e:
        logger.error(f"Mistral search error: {e}")
        return "Kh√¥ng th·ªÉ t√¨m ki·∫øm b·∫±ng Mistral"

def get_recommendations(query, similarity_matrix, books_df, ix):
    try:
        # T√¨m ki·∫øm v·ªõi Whoosh tr√™n nhi·ªÅu tr∆∞·ªùng bao g·ªìm authors v√† published_year
        with ix.searcher() as searcher:
            # T√¨m ki·∫øm chung tr√™n c√°c tr∆∞·ªùng text
            text_parser = MultifieldParser(["title", "description", "category", "authors"], schema=schema)
            text_q = text_parser.parse(query)
            text_results = searcher.search(text_q, limit=10)
            logger.debug(f"Whoosh text results for '{query}': {len(text_results)} matches")

            # T√¨m ki·∫øm ri√™ng cho published_year
            year_parser = QueryParser("published_year", schema=schema)
            try:
                year_value = int(query)  # Th·ª≠ chuy·ªÉn query th√†nh s·ªë
                year_q = year_parser.parse(str(year_value))
                year_results = searcher.search(year_q, limit=10)
                logger.debug(f"Whoosh year results for '{query}': {len(year_results)} matches")
            except ValueError:
                year_results = []  # N·∫øu kh√¥ng ph·∫£i s·ªë, b·ªè qua

            # K·∫øt h·ª£p k·∫øt qu·∫£
            whoosh_results = set()
            for r in text_results:
                match = books_df[books_df['title'].str.lower() == r['title'].lower()]
                if not match.empty:
                    whoosh_results.add(match.index[0])
            for r in year_results:
                match = books_df[books_df['title'].str.lower() == r['title'].lower()]
                if not match.empty:
                    whoosh_results.add(match.index[0])

            if whoosh_results:
                whoosh_results_df = books_df.loc[list(whoosh_results)]
                logger.debug(f"Combined Whoosh results: {len(whoosh_results_df)} books")
                return whoosh_results_df

        # N·∫øu kh√¥ng t√¨m th·∫•y, d√πng TF-IDF v·ªõi ki·ªÉm tra li√™n quan
        vectorizer = TfidfVectorizer(stop_words='english', max_features=5000, max_df=1.0, min_df=1)
        combined_features = (books_df['title'].astype(str).replace('', ' ') + ' ' +
                            books_df['description'].astype(str).replace('', ' ') + ' ' +
                            books_df['category'].astype(str).replace('', ' ') + ' ' +
                            books_df['authors'].astype(str).replace('', ' '))
        tfidf_matrix_query = vectorizer.fit_transform([query])
        tfidf_matrix_books = vectorizer.transform(combined_features)
        logger.debug(f"TF-IDF matrix shape: {tfidf_matrix_books.shape}")
        similarity_scores = cosine_similarity(tfidf_matrix_query, tfidf_matrix_books).flatten()
        logger.debug(f"Similarity scores shape: {similarity_scores.shape}")

        # L·ªçc c√°c s√°ch c√≥ ƒë·ªô t∆∞∆°ng ƒë·ªìng c∆° b·∫£n (>= 0.2)
        relevant_indices = np.where(similarity_scores >= 0.2)[0]
        if len(relevant_indices) == 0:
            logger.debug(f"No books with basic relevance (>= 0.2) for '{query}'")
            return pd.DataFrame()

        # L·ªçc theo published_year n·∫øu query l√† s·ªë
        try:
            year_value = int(query)
            year_indices = books_df.index[books_df['published_year'] == year_value].tolist()
            relevant_indices = np.intersect1d(relevant_indices, year_indices) if year_indices else relevant_indices
            logger.debug(f"Filtered by year {year_value}: {len(relevant_indices)} matches")
        except ValueError:
            logger.debug(f"Query '{query}' is not a year, skipping year filter")

        # L·∫•y ch·ªâ s·ªë c√≥ ƒë·ªô t∆∞∆°ng ƒë·ªìng >= 0.9 t·ª´ c√°c s√°ch li√™n quan
        high_similarity_indices = np.intersect1d(relevant_indices, np.where(similarity_scores >= 0.9)[0])
        logger.debug(f"TF-IDF high similarity scores for '{query}': {len(high_similarity_indices)} matches above 0.9")
        if len(high_similarity_indices) > 0:
            top_indices = high_similarity_indices[np.argsort(similarity_scores[high_similarity_indices])[-5:]]  # Top 5 cao nh·∫•t
            return books_df.iloc[top_indices]
        else:
            logger.debug(f"No books with high similarity (>= 0.9) for '{query}'")
            return pd.DataFrame()

    except Exception as e:
        logger.error(f"Recommendation error: {e}")
        return pd.DataFrame()

def display_cover(image_url):
    # S·ª≠ d·ª•ng ch√≠nh x√°c m√£ b·∫°n cung c·∫•p, kh√¥ng th√™m ki·ªÉm tra l·ªói
    return image_url if pd.notna(image_url) and image_url.strip() else 'cover-not-found.jpg'

# Kh·ªüi t·∫°o state (ch·ªâ g·ªçi m·ªôt l·∫ßn khi ·ª©ng d·ª•ng kh·ªüi ƒë·ªông)
def init_state():
    if 'initialized' not in st.session_state:
        st.session_state.selected_book = None
        st.session_state.search_results = None  # Th√™m bi·∫øn ƒë·ªÉ l∆∞u k·∫øt qu·∫£ t√¨m ki·∫øm
        st.session_state.initialized = True
    logger.debug("Initialized session state: selected_book={}, search_results={}".format(
        st.session_state.selected_book, st.session_state.search_results))

# Hi·ªÉn th·ªã danh s√°ch s√°ch (top ho·∫∑c k·∫øt qu·∫£ t√¨m ki·∫øm)
def display_books(books_df, title="Danh s√°ch s√°ch"):
    st.subheader(title)
    logger.debug(f"Displaying {len(books_df)} books for {title} with columns: {books_df.columns.tolist()}")
    for i in range(0, min(len(books_df), 50), 5):  # Hi·ªÉn th·ªã t·ªëi ƒëa 50 s√°ch
        cols = st.columns(5)
        for j, col in enumerate(cols):
            if i + j < len(books_df):
                book = books_df.iloc[i + j].to_dict()
                with col:
                    st.image(display_cover(book['thumbnail']), width=150)
                    st.write(f"**{book['title']}**")
                    st.write(f"Rating: {int(book['ratings_count']) if pd.notna(book['ratings_count']) else 0}")
                    if st.button("Xem", key=f"{title.replace(' ', '_')}_{i+j}"):
                        logger.debug(f"View clicked for book: {book['title']} from {title}, data: {book}")
                        st.session_state.selected_book = book
                        st.rerun()

# Hi·ªÉn th·ªã th√¥ng tin chi ti·∫øt (pop-up)
def display_book_details(books_df, similarity_matrix):
    if st.session_state.selected_book is not None:
        book = st.session_state.selected_book
        logger.debug(f"Displaying details for book: {book['title']}, data: {book}")
        if not all(key in book for key in ['title', 'thumbnail', 'description', 'authors', 'published_year', 'categories', 'ratings_count']):
            st.error(f"D·ªØ li·ªáu s√°ch kh√¥ng ƒë·∫ßy ƒë·ªß: {book}")
            st.session_state.selected_book = None
            st.rerun()
            return
        st.markdown("---")
        st.subheader("üìñ Chi ti·∫øt s√°ch")
        col1, col2 = st.columns([1, 3])
        with col1:
            st.image(display_cover(book['thumbnail']), width=300)
        with col2:
            st.write(f"**T·ª±a ƒë·ªÅ:** {book['title']}")
            st.write(f"**T√°c gi·∫£:** {book.get('authors', 'Unknown')}")
            st.write(f"**NƒÉm xu·∫•t b·∫£n:** {book.get('published_year', 'N/A')}")
            st.write(f"**Th·ªÉ lo·∫°i:** {book.get('categories', 'N/A')}")
            st.write(f"**M√¥ t·∫£:** {book.get('description', 'No description available')}")
            st.write(f"**S·ªë l∆∞·ª£t ƒë√°nh gi√°:** {int(book.get('ratings_count', 0))}")
        st.subheader("üìö S√°ch t∆∞∆°ng t·ª±")
        try:
            # Ki·ªÉm tra xem ti√™u ƒë·ªÅ c√≥ t·ªìn t·∫°i trong books_df
            matching_books = books_df[books_df['title'].str.lower() == book['title'].lower()]  # So s√°nh kh√¥ng ph√¢n bi·ªát ch·ªØ c√°i
            if matching_books.empty:
                logger.error(f"No matching book found for title: {book['title']}")
                st.write("Kh√¥ng th·ªÉ t√¨m th·∫•y s√°ch n√†y trong d·ªØ li·ªáu.")
            else:
                idx = matching_books.index[0]
                logger.debug(f"Found index for {book['title']}: {idx}, books_df length: {len(books_df)}")
                if similarity_matrix is not None and 0 <= idx < similarity_matrix.shape[0]:
                    similar_scores = similarity_matrix[idx]
                    if np.any(np.isnan(similar_scores)):  # Ki·ªÉm tra NaN
                        logger.error(f"NaN values found in similarity scores for index {idx}")
                        st.write("Kh√¥ng th·ªÉ t·∫£i s√°ch t∆∞∆°ng t·ª± do d·ªØ li·ªáu ma tr·∫≠n kh√¥ng h·ª£p l·ªá.")
                    else:
                        similar_indices = similar_scores.argsort()[::-1][1:6]  # 5 s√°ch t∆∞∆°ng t·ª±, b·ªè qua ch√≠nh n√≥
                        if len(similar_indices) > 0 and all(0 <= i < len(books_df) for i in similar_indices):
                            similar_books = books_df.iloc[similar_indices]
                            if not similar_books.empty:
                                for _, similar_book in similar_books.iterrows():
                                    st.write(f"- {similar_book['title']}")
                            else:
                                logger.warning(f"No valid similar books found for index {idx}")
                                st.write("Kh√¥ng t√¨m th·∫•y s√°ch t∆∞∆°ng t·ª± h·ª£p l·ªá.")
                        else:
                            logger.warning(f"Similar indices out of range for index {idx}")
                            st.write("Kh√¥ng t√¨m th·∫•y s√°ch t∆∞∆°ng t·ª± do ch·ªâ s·ªë kh√¥ng h·ª£p l·ªá.")
                else:
                    logger.error(f"Similarity matrix issue: idx={idx}, matrix shape={similarity_matrix.shape if similarity_matrix is not None else 'None'}, books_df length={len(books_df)}")
                    st.write("Kh√¥ng th·ªÉ t·∫£i s√°ch t∆∞∆°ng t·ª± do l·ªói ma tr·∫≠n t∆∞∆°ng ƒë·ªìng.")
        except Exception as e:
            logger.error(f"Error getting similar books: {e}")
            st.write(f"Kh√¥ng th·ªÉ t·∫£i s√°ch t∆∞∆°ng t·ª± do l·ªói: {str(e)}")

        if st.button("üîô ƒê√≥ng"):
            logger.debug(f"Closing details for book: {book['title']}")
            st.session_state.selected_book = None
            st.rerun()

# Main UI
def main():
    # Ch·ªâ g·ªçi init_state m·ªôt l·∫ßn khi ·ª©ng d·ª•ng kh·ªüi ƒë·ªông
    if 'initialized' not in st.session_state:
        init_state()

    st.title("üìö Book Recommendation System")

    # Load d·ªØ li·ªáu
    books_df = load_data()
    if books_df.empty:
        return
    similarity_matrix = compute_similarity(books_df)
    global ix
    try:
        ix = create_or_open_index(books_df)
    except Exception as e:
        logger.error(f"Error creating or opening index: {e}")
        st.error(f"L·ªói khi t·∫°o ho·∫∑c m·ªü index: {str(e)}")
        return

    # ∆Øu ti√™n hi·ªÉn th·ªã chi ti·∫øt n·∫øu selected_book t·ªìn t·∫°i
    if st.session_state.selected_book is not None:
        logger.debug("Showing details due to selected_book")
        display_book_details(books_df, similarity_matrix)
        return

    # Search UI
    with st.form(key='search_form', clear_on_submit=False):
        search_input = st.text_input("üîç Nh·∫≠p t·ª´ kh√≥a s√°ch")
        search_button = st.form_submit_button("T√¨m ki·∫øm")

    # X·ª≠ l√Ω t√¨m ki·∫øm
    if search_button and search_input:
        recommendations = get_recommendations(search_input, similarity_matrix, books_df, ix)
        logger.debug(f"Recommendations for '{search_input}': {len(recommendations)} books, columns: {recommendations.columns.tolist()}")
        if not recommendations.empty:
            st.session_state.search_results = recommendations  # L∆∞u k·∫øt qu·∫£ t√¨m ki·∫øm
            display_books(recommendations, f"üìñ K·∫øt qu·∫£ t√¨m ki·∫øm cho n·ªôi dung b·∫°n t√¨m ki·∫øm")
        else:
            st.write(f"Kh√¥ng t√¨m th·∫•y s√°ch n√†o li√™n quan ƒë·∫øn n·ªôi dung b·∫°n t√¨m ki·∫øm .")

    # Hi·ªÉn th·ªã top s√°ch ho·∫∑c k·∫øt qu·∫£ t√¨m ki·∫øm tr∆∞·ªõc ƒë√≥ khi kh√¥ng ·ªü ch·∫ø ƒë·ªô chi ti·∫øt
    if st.session_state.selected_book is None:
        if st.session_state.search_results is not None:
            display_books(st.session_state.search_results, f"üìñ K·∫øt qu·∫£ t√¨m ki·∫øm g·∫ßn ƒë√¢y")
        else:
            display_books(books_df.nlargest(50, 'ratings_count'), "üî• Top 50 s√°ch n·ªïi b·∫≠t")

if __name__ == "__main__":
    main()