import streamlit as st
import pandas as pd
import logging
import numpy as np
from whoosh.index import create_in, open_dir
from whoosh.fields import Schema, TEXT, NUMERIC
from whoosh.qparser import MultifieldParser
from diskcache import Cache
from concurrent.futures import ThreadPoolExecutor, TimeoutError
import ollama
import os
from pathlib import Path
import time
import requests
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from scipy.sparse import csr_matrix

# C·∫•u h√¨nh logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# C·∫•u h√¨nh Streamlit
st.set_page_config(layout="wide", page_title="Book Recommendation ", initial_sidebar_state="expanded")

# ƒê∆∞·ªùng d·∫´n index Whoosh v√† cache
INDEX_DIR = Path("indexdir")
CACHE_DIR = Path("./cache")

# T·∫°o schema Whoosh
schema = Schema(
    title=TEXT(stored=True),
    authors=TEXT(stored=True),
    published_year=NUMERIC(stored=True),
    category=TEXT(stored=True),
    description=TEXT(stored=True),
    thumbnail=TEXT(stored=True),
    ratings_count=NUMERIC(stored=True)
)

# Kh·ªüi t·∫°o index Whoosh
def create_or_open_index(books_df):
    if not INDEX_DIR.exists():
        os.makedirs(INDEX_DIR)
        ix = create_in(INDEX_DIR, schema)
        writer = ix.writer()
        for _, row in books_df.iterrows():
            writer.add_document(
                title=str(row['title']),
                authors=str(row['authors']),
                published_year=int(row['published_year']) if pd.notna(row['published_year']) else 0,
                category=str(row['categories']),
                description=str(row['description']),
                thumbnail=str(row['thumbnail'] if pd.notna(row['thumbnail']) else ''),
                ratings_count=float(row['ratings_count']) if pd.notna(row['ratings_count']) else 0
            )
        writer.commit()
        logger.info(f"Created new Whoosh index in {INDEX_DIR}")
    else:
        ix = open_dir(INDEX_DIR)
    return ix

# Kh·ªüi t·∫°o cache
cache = Cache(CACHE_DIR)

# S·ªë lu·ªìng t√¨m ki·∫øm song song
executor = ThreadPoolExecutor(max_workers=2)

# Cache d·ªØ li·ªáu t·ª´ books.csv
@st.cache_data(hash_funcs={pd.DataFrame: lambda x: hash(x.to_string())})
def load_data():
    try:
        if not os.path.exists('books.csv'):
            logger.error("File 'books.csv' not found")
            st.error("Kh√¥ng t√¨m th·∫•y file 'books.csv'. Vui l√≤ng ki·ªÉm tra l·∫°i.")
            return pd.DataFrame()
        books_df = pd.read_csv('books.csv', usecols=[
            'title', 'description', 'authors', 'categories',
            'published_year', 'ratings_count', 'thumbnail'
        ], dtype={
            'title': 'string', 'description': 'string', 'authors': 'string',
            'categories': 'string', 'published_year': 'Int32',
            'ratings_count': 'float32', 'thumbnail': 'string'
        })
        books_df.fillna({
            'description': 'None', 'authors': 'None',
            'categories': 'None', 'thumbnail': ''
        }, inplace=True)
        books_df['ratings_count'] = books_df['ratings_count'].fillna(0)
        logger.info(f"Loaded dataset with {len(books_df)} books")
        return books_df
    except Exception as e:
        logger.error(f"Error loading data: {e}")
        st.error("Kh√¥ng th·ªÉ t·∫£i d·ªØ li·ªáu s√°ch")
        return pd.DataFrame()

@st.cache_resource
def compute_similarity(df):
    try:
        vectorizer = TfidfVectorizer(stop_words='english', max_features=5000,
                                   max_df=1.0, min_df=1)  # ƒêi·ªÅu ch·ªânh max_df v√† min_df
        combined_features = df['title'] + ' ' + df['description']
        tfidf_matrix = vectorizer.fit_transform(combined_features)
        sparse_tfidf = csr_matrix(tfidf_matrix)
        similarity_matrix = cosine_similarity(sparse_tfidf)
        return similarity_matrix
    except Exception as e:
        logger.error(f"Error computing similarity: {e}")
        return None

@st.cache_data
def mistral_search(query):
    try:
        future = executor.submit(ollama.chat, model="mistral", messages=[
            {"role": "system", "content": "You are a book recommendation assistant. Only return titles that are highly relevant to the query based on scientific or factual content."},
            {"role": "user", "content": f"Find relevant book titles for: {query}"}
        ])
        response = future.result(timeout=10)
        return response["message"]["content"].strip()
    except TimeoutError:
        logger.warning(f"Mistral query for '{query}' timed out after 10s")
        return "Kh√¥ng th·ªÉ t√¨m ki·∫øm b·∫±ng Mistral"
    except Exception as e:
        logger.error(f"Mistral search error: {e}")
        return "Kh√¥ng th·ªÉ t√¨m ki·∫øm b·∫±ng Mistral"

def get_recommendations(query, similarity_matrix, books_df, ix):
    try:
        # T√¨m ki·∫øm v·ªõi Whoosh tr√™n nhi·ªÅu tr∆∞·ªùng
        with ix.searcher() as searcher:
            parser = MultifieldParser(["title", "description", "category"], schema=schema)  # Th√™m category
            q = parser.parse(query)
            results = searcher.search(q, limit=5)  # TƒÉng limit ƒë·ªÉ l·∫•y nhi·ªÅu k·∫øt qu·∫£ h∆°n
            logger.debug(f"Whoosh results for '{query}': {len(results)} matches")
            if results:
                whoosh_results = []
                for r in results:
                    match = books_df[books_df['title'].str.lower() == r['title'].lower()]
                    book_data = match.iloc[0].to_dict() if not match.empty else {
                        'title': r['title'],
                        'description': r['description'],
                        'authors': r.get('authors', 'None'),
                        'published_year': r.get('published_year', 0),
                        'category': r.get('category', 'None'),
                        'thumbnail': r.get('thumbnail', ''),
                        'ratings_count': r.get('ratings_count', 0)
                    }
                    # Ki·ªÉm tra n·∫øu t·ª´ kh√≥a xu·∫•t hi·ªán trong description ho·∫∑c category
                    if query.lower() in (book_data['description'].lower() if book_data['description'] else '') or \
                       query.lower() in (book_data['category'].lower() if book_data['category'] else ''):
                        whoosh_results.append(book_data)
                if whoosh_results:
                    return pd.DataFrame(whoosh_results)

        # N·∫øu kh√¥ng t√¨m th·∫•y, d√πng TF-IDF v·ªõi ki·ªÉm tra li√™n quan
        vectorizer = TfidfVectorizer(stop_words='english', max_features=5000, max_df=1.0, min_df=1)
        combined_features = books_df['title'] + ' ' + books_df['description'] + ' ' + books_df['category']
        tfidf_matrix_query = vectorizer.fit_transform([query])  # Vectorize query
        tfidf_matrix_books = vectorizer.transform(combined_features)
        logger.debug(f"TF-IDF matrix shape: {tfidf_matrix_books.shape}")
        similarity_scores = cosine_similarity(tfidf_matrix_query, tfidf_matrix_books).flatten()
        logger.debug(f"Similarity scores shape: {similarity_scores.shape}")

        # L·ªçc c√°c s√°ch c√≥ ƒë·ªô t∆∞∆°ng ƒë·ªìng c∆° b·∫£n (>= 0.3) ƒë·ªÉ ƒë·∫£m b·∫£o li√™n quan
        relevant_indices = np.where(similarity_scores >= 0.1)[0]
        if len(relevant_indices) == 0:
            logger.debug(f"No books with basic relevance (>= 0.1) for '{query}'")
            return pd.DataFrame()

        # L·∫•y ch·ªâ s·ªë c√≥ ƒë·ªô t∆∞∆°ng ƒë·ªìng >= 90% t·ª´ c√°c s√°ch li√™n quan
        high_similarity_indices = np.intersect1d(relevant_indices, np.where(similarity_scores >= 0.9)[0])
        logger.debug(f"TF-IDF high similarity scores for '{query}': {len(high_similarity_indices)} matches above 0.9")
        if len(high_similarity_indices) > 0:
            top_indices = high_similarity_indices[np.argsort(similarity_scores[high_similarity_indices])[-5:]]  # Top 5 cao nh·∫•t
            return books_df.iloc[top_indices]
        else:
            logger.debug(f"No books with high similarity (>= 0.9) for '{query}'")
            return pd.DataFrame()

    except Exception as e:
        logger.error(f"Recommendation error: {e}")
        return pd.DataFrame()

def display_cover(image_url):
    # S·ª≠ d·ª•ng ch√≠nh x√°c m√£ b·∫°n cung c·∫•p, kh√¥ng th√™m ki·ªÉm tra l·ªói
    return image_url if pd.notna(image_url) and image_url.strip() else 'cover-not-found.jpg'

# Kh·ªüi t·∫°o state (ch·ªâ g·ªçi m·ªôt l·∫ßn khi ·ª©ng d·ª•ng kh·ªüi ƒë·ªông)
def init_state():
    if 'initialized' not in st.session_state:
        st.session_state.selected_book = None
        st.session_state.search_results = None  # Th√™m bi·∫øn ƒë·ªÉ l∆∞u k·∫øt qu·∫£ t√¨m ki·∫øm
        st.session_state.initialized = True
    logger.debug("Initialized session state: selected_book={}, search_results={}".format(
        st.session_state.selected_book, st.session_state.search_results))

# Hi·ªÉn th·ªã danh s√°ch s√°ch (top ho·∫∑c k·∫øt qu·∫£ t√¨m ki·∫øm)
def display_books(books_df, title="Danh s√°ch s√°ch"):
    st.subheader(title)
    logger.debug(f"Displaying {len(books_df)} books for {title} with columns: {books_df.columns.tolist()}")
    for i in range(0, min(len(books_df), 50), 5):  # Hi·ªÉn th·ªã t·ªëi ƒëa 50 s√°ch
        cols = st.columns(5)
        for j, col in enumerate(cols):
            if i + j < len(books_df):
                book = books_df.iloc[i + j].to_dict()
                with col:
                    st.image(display_cover(book['thumbnail']), width=150)
                    st.write(f"**{book['title']}**")
                    st.write(f"Rating: {int(book['ratings_count']) if pd.notna(book['ratings_count']) else 0}")
                    if st.button("Xem", key=f"{title.replace(' ', '_')}_{i+j}"):
                        logger.debug(f"View clicked for book: {book['title']} from {title}, data: {book}")
                        st.session_state.selected_book = book
                        st.rerun()

# Hi·ªÉn th·ªã th√¥ng tin chi ti·∫øt (pop-up)
def display_book_details(books_df, similarity_matrix):
    if st.session_state.selected_book is not None:
        book = st.session_state.selected_book
        logger.debug(f"Displaying details for book: {book['title']}, data: {book}")
        if not all(key in book for key in ['title', 'thumbnail', 'description', 'authors', 'published_year', 'categories', 'ratings_count']):
            st.error(f"D·ªØ li·ªáu s√°ch kh√¥ng ƒë·∫ßy ƒë·ªß: {book}")
            st.session_state.selected_book = None
            st.rerun()
            return
        st.markdown("---")
        st.subheader("üìñ Chi ti·∫øt s√°ch")
        col1, col2 = st.columns([1, 3])
        with col1:
            st.image(display_cover(book['thumbnail']), width=300)
        with col2:
            st.write(f"**T·ª±a ƒë·ªÅ:** {book['title']}")
            st.write(f"**T√°c gi·∫£:** {book.get('authors', 'Unknown')}")
            st.write(f"**NƒÉm xu·∫•t b·∫£n:** {book.get('published_year', 'N/A')}")
            st.write(f"**Th·ªÉ lo·∫°i:** {book.get('categories', 'N/A')}")
            st.write(f"**M√¥ t·∫£:** {book.get('description', 'No description available')}")
            st.write(f"**S·ªë l∆∞·ª£t ƒë√°nh gi√°:** {int(book.get('ratings_count', 0))}")
        st.subheader("üìö S√°ch t∆∞∆°ng t·ª±")
        try:
            idx = books_df[books_df['title'] == book['title']].index[0]
            similar_indices = similarity_matrix[idx].argsort()[::-1][1:6]  # 5 s√°ch t∆∞∆°ng t·ª±
            similar_books = books_df.iloc[similar_indices]
            for _, similar_book in similar_books.iterrows():
                st.write(f"- {similar_book['title']}")
        except Exception as e:
            logger.error(f"Error getting similar books: {e}")
            st.write("Kh√¥ng th·ªÉ t·∫£i s√°ch t∆∞∆°ng t·ª±.")
        if st.button("üîô ƒê√≥ng"):
            logger.debug(f"Closing details for book: {book['title']}")
            st.session_state.selected_book = None
            st.rerun()

# Main UI
def main():
    # Ch·ªâ g·ªçi init_state m·ªôt l·∫ßn khi ·ª©ng d·ª•ng kh·ªüi ƒë·ªông
    if 'initialized' not in st.session_state:
        init_state()

    st.title("üìö Book Recommendation System")

    # Load d·ªØ li·ªáu
    books_df = load_data()
    if books_df.empty:
        return
    similarity_matrix = compute_similarity(books_df)
    global ix
    try:
        ix = create_or_open_index(books_df)
    except Exception as e:
        logger.error(f"Error creating or opening index: {e}")
        st.error(f"L·ªói khi t·∫°o ho·∫∑c m·ªü index: {str(e)}")
        return

    # ∆Øu ti√™n hi·ªÉn th·ªã chi ti·∫øt n·∫øu selected_book t·ªìn t·∫°i
    if st.session_state.selected_book is not None:
        logger.debug("Showing details due to selected_book")
        display_book_details(books_df, similarity_matrix)
        return

    # Search UI
    with st.form(key='search_form', clear_on_submit=False):
        search_input = st.text_input("üîç Nh·∫≠p t·ª´ kh√≥a s√°ch")
        search_button = st.form_submit_button("T√¨m ki·∫øm")

    # X·ª≠ l√Ω t√¨m ki·∫øm
    if search_button and search_input:
        recommendations = get_recommendations(search_input, similarity_matrix, books_df, ix)
        logger.debug(f"Recommendations for '{search_input}': {len(recommendations)} books, columns: {recommendations.columns.tolist()}")
        if not recommendations.empty:
            st.session_state.search_results = recommendations  # L∆∞u k·∫øt qu·∫£ t√¨m ki·∫øm
            display_books(recommendations, f"üìñ K·∫øt qu·∫£ t√¨m ki·∫øm cho n·ªôi dung b·∫°n t√¨m ki·∫øm")
        else:
            st.write(f"Kh√¥ng t√¨m th·∫•y s√°ch n√†o li√™n quan ƒë·∫øn n·ªôi dung b·∫°n t√¨m ki·∫øm .")

    # Hi·ªÉn th·ªã top s√°ch ho·∫∑c k·∫øt qu·∫£ t√¨m ki·∫øm tr∆∞·ªõc ƒë√≥ khi kh√¥ng ·ªü ch·∫ø ƒë·ªô chi ti·∫øt
    if st.session_state.selected_book is None:
        if st.session_state.search_results is not None:
            display_books(st.session_state.search_results, f"üìñ K·∫øt qu·∫£ t√¨m ki·∫øm g·∫ßn ƒë√¢y")
        else:
            display_books(books_df.nlargest(50, 'ratings_count'), "üî• Top 50 s√°ch n·ªïi b·∫≠t")

if __name__ == "__main__":
    main()